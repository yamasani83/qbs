{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Countries\n",
    "\n",
    "This section was adapted from code and instructions provided by Shivangi Patel [\"A Complete Guide to an Interactive Geographical Map using Python\"](https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0). Any cells marked with \"Patel\" comes from this guide.\n",
    "\n",
    "We will first import a shapefile with boundaries for the world's 258 countries (downloaded from Natural Earth. Note: they identify 258 countries but only 208 sovereign states).\n",
    "\n",
    "*To understand how this code works, it is recommended you try tweaking different lines of code (to see how the output differs), print / output some variables to see what kind of data is contained within, and break code cells into smaller parts and run those smaller chunks one at a time, inspecting what each does.*  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       #for working with dataframes\n",
    "import geopandas as gpd   #... with geodataframes\n",
    "import spacy              # NLP\n",
    "import collections        # freq lists\n",
    "import country_converter as coco   #for standardizing country names\n",
    "import json\n",
    "from spacy.lang.en.examples import sentences\n",
    "from spacy import displacy\n",
    "\n",
    "#in addition to matplotlib, seaborn, and plotly, bokeh is a 4th powerful visualization library for Python\n",
    "from bokeh.io import output_notebook, show, output_file #bokeh - viz package\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar\n",
    "from bokeh.palettes import brewer  #Input GeoJSON source that contains features for plotting.\n",
    "from bokeh.models import ContinuousColorMapper, EqHistColorMapper, LogColorMapper\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Import and Set Up a Dataframe of Countries\n",
    "\n",
    "1. Import a shapefile using **Geopandas** as a geo-dataframe, then subset it, keeping only the columns we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Patel]\n",
    "\n",
    "shapefile = \"countries_110m/ne_110m_admin_0_countries.shp\"\n",
    "\n",
    "#Read shapefile using Geopandas\n",
    "gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]\n",
    "\n",
    "#Rename columns.\n",
    "gdf.columns = ['country', 'country_code', 'geometry']\n",
    "gdf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Patel]: 3. We can drop the row for ‘Antarctica’ as it unnecessarily occupies a large space in our map and is not required in our current analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf[gdf['country'] == 'Antarctica']) #Drop row corresponding to 'Antarctica'\n",
    "gdf = gdf.drop(gdf.index[159])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Standardize & Count Countries Mentioned in SOTU\n",
    "\n",
    "4. To standardize country names, we can use the [**country_converter**](https://notebook.community/konstantinstadler/country_converter/doc/country_converter_examples) package. Let's try it with some examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "some_names = ['United Rep. of Tanzania', 'DE', 'Cape Verde', '788', 'Burma', 'COG',\n",
    "              'Iran (Islamic Republic of)', 'Korea, Republic of',\n",
    "              \"Dem. People's Rep. of Korea\"]\n",
    "standard_names = coco.convert(names = some_names, to = 'name_short')\n",
    "print(standard_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b. We can also use a three-digit (\"iso3\") code that serves as a unique identifier for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_list = list(gdf['country'])\n",
    "print(countries_list[:10])\n",
    "countries_iso3 = coco.convert(names = countries_list, to = 'ISO3')\n",
    "countries_iso3[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><p style=\"color:green\">5. Try applying a list of countries of your choosing through the coco.convert function and examine the results.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. To extract countries from our the Biden 2023 SOTU, we will want to focus on the GPE named entities. The following code extracts GPEs only and then creates a frequency list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf = pd.read_csv(\"sotudf.tsv\", encoding=\"utf-8\", sep=\"\\t\", index_col=0)\n",
    "sotudf = sotudf.sort_values(by = ['year'])\n",
    "biden23text = sotudf[sotudf['year'] == 2023]['fulltext'].item()\n",
    "doc = nlp(biden23text)\n",
    "ents = [(e.text, e.label_, e.kb_id_) for e in doc.ents]\n",
    "sotu_gpes = [ent[0] for ent in ents if ent[1] == 'GPE']\n",
    "sotu_gpes_freqs = collections.Counter(sotu_gpes)\n",
    "sotu_gpes_freqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. We can use list comprehensions to standardize our country names before re-compiling our frequency list. We want to do two quick tasks:\n",
    "+ replace \"America\" with \"United States\" as the country_converter does not have \"America\" listed as one of its aliases for the USA.\n",
    "+ convert all remaining countries in our list of geopolitical entities (GPEs) extracted from the Biden speech into their iso-3 code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"original list:\", sotu_gpes)\n",
    "sotu_countries = [\"United States\" if country == \"America\" else country for country in sotu_gpes]\n",
    "print(\"with 'America' replaced: \", sotu_countries)\n",
    "sotu_countries_std = [coco.convert(country, to = \"ISO3\") for country in sotu_countries]\n",
    "print(\"with iso3 codes:\", sotu_countries_std)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Now, let's see how our frequency has changes since Step 6 above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(sotu_countries_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can then save this freq list into memory\n",
    "sotu_countries_std_freqs = collections.Counter(sotu_countries_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Merge country frequency list (actually a dictionary) with geoPandas dataframe created from country shapefile\n",
    "\n",
    "9. Convert country frequency dictionary into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu_countries_freqs_df = pd.DataFrame.from_dict(sotu_countries_std_freqs, orient = 'index', columns = ['freq'])\n",
    "sotu_countries_freqs_df.index.name = \"iso3\"\n",
    "sotu_countries_freqs_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. We can remove the \"not found\" countries using the **.drop() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu_countries_freqs_df.drop(['not found'], inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. We now want to merge our new dataframe of countries listed in the Biden 23 address with our geoPandas dataframe. First let's review our countries geo-dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merged = gdf.merge(sotu_countries_freqs_df, left_on = \"country_code\", right_index = True, how = \"outer\")\n",
    "# I used \"outer\" above to include all countries, not just those that appeared in the SOTU address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merged\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Often it helps maintain a consistent data type in our columns. In this case, we want to replace the \"NaN\"'s in the freq column with 0's and then convert that column into all integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merged['freq'] = gdf_merged['freq'].fillna(0)\n",
    "gdf_merged['freq'] = gdf_merged['freq'].astype(int)\n",
    "gdf_merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. [Patel] The merged file is a GeoDataframe object that can be rendered using geopandas module. However, since we want to incorporate data visualization interactivity, we will use Bokeh library. Bokeh consumes GeoJSON format which represents geographical features with JSON. GeoJSON describes points, lines and polygons (called Patches in Bokeh) as a collection of features. We therefore convert the merged file to GeoJSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json   #Read data to json.\n",
    "gdf_json = json.loads(gdf_merged.to_json())#Convert to String like object.\n",
    "json_data = json.dumps(gdf_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. We are now ready to render our choropleth map using Bokeh. Import the required modules. The code is described inline. [Patel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brewer['YlGnBu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geosource = GeoJSONDataSource(geojson = json_data)  #Define a sequential multi-hue color palette.\n",
    "palette = brewer['YlGnBu'][8]  #Reverse color order so that dark blue is highest obesity.\n",
    "palette = palette[::-1]  #Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors.\n",
    "color_mapper = LinearColorMapper(palette = palette, low = 1, low_color = \"white\")   #Define custom tick labels for color bar.\n",
    "#tick_labels = {'0': '0%', '5': '5%', '10':'10%', '15':'15%', '20':'20%', '25':'25%', '30':'30%','35':'35%', '40': '>40%'}  #Create color bar. \n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8, width = 500, height = 20, border_line_color=None,location = (0,0), orientation = 'horizontal') #, major_label_overrides = tick_labels)  #Create figure object.\n",
    "p = figure(title = \"Countries mentioned in Biden's 2023 SOTU address\", plot_height = 600 , plot_width = 950, toolbar_location = None)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None  #Add patch renderer to figure. \n",
    "p.patches('xs','ys', source = geosource,fill_color = {'field' :'freq', 'transform' : color_mapper},\n",
    "          line_color = 'black', line_width = 0.25, fill_alpha = 1)  #Specify figure layout.\n",
    "p.add_layout(color_bar, 'below')  #Display figure inline in Jupyter Notebook.\n",
    "output_notebook()  #Display figure.\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Map the entire SOTU Corpus\n",
    "\n",
    "13. Given what you have learned, what steps will we need to complete in order to create a map of all countries listed across the entire corpus. Write your answer down in the empty markdown cell(s) below.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Review the code below. Identify what each of the following steps does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGPES(text):\n",
    "    if pd.isnull(text):\n",
    "        gpes = []\n",
    "    else:\n",
    "        doc = nlp(text)\n",
    "        gpes = [e.text for e in doc.ents if e.label_ == \"GPE\"]\n",
    "    return(gpes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractGPES(sotudf.iloc[1]['fulltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. We can now apply this function across our dataframe of SOTU addresses. **NOTE: this will take several minutes to run (nearly 5 minutes on my fast computer). This might be a good time to do something else (take a break, discuss your projects, etc.) while waiting for it to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf['gpes'] = sotudf['fulltext'].apply(extractGPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. The cell below combines all GPEs list for each individual SOTU address in the 'gpes' column into one large list. There are certainly other ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gpes = [a for b in sotudf.gpes.tolist() for a in b]\n",
    "all_gpes[-30:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. We want to replace all instances of 'America' in this GPE list with 'United States':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gpes = list(map(lambda x: x.replace('America', 'United States'), all_gpes))\n",
    "all_gpes[-30:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. We can use the **collections** package to identify the most frequent GPEs mentioned in the SOTU addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gpes_freqs = collections.Counter(all_gpes)\n",
    "print(type(all_gpes_freqs))\n",
    "all_gpes_freqs.most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gpes_freqs.items()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. As you can see above, we have multiple different aliases referring to the United States. The code below uses the **country_converter** packages (imported as \"coco\") to standardize country references as a three-digit ISO code. We then will calculate a cumulative sum for each country. For example, in the above we have: \n",
    "\n",
    "```\n",
    "('the United States', 3133),\n",
    "('United States', 2126),\n",
    "('the United\\nStates', 366)\n",
    "```\n",
    "\n",
    "Identifying these all under the iso3 code \"USA\" and summing their totals would return: \n",
    "\n",
    "```\n",
    "(USA, 5625)\n",
    "```\n",
    "\n",
    "The actual total for \"USA\" is probably higher as their our undoubtedly other variations within the SOTU address. But, you get the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allsotu_countries_freqs_iso3 = {coco.convert(k, to = \"ISO3\"):v for (k, v) in all_gpes_freqs.items()}\n",
    "all_gpes_freqs_iso3 = {}\n",
    "for (k, v) in all_gpes_freqs.items():\n",
    "    new_k = coco.convert(k, to = \"ISO3\")\n",
    "    #sometimes country_converter returns two possible candidates in a list, i.e. \"United States of Colombia\" --> ['COL', 'USA']\n",
    "    ##the if statement below just extracts the first answer from the list\n",
    "    if type(new_k) == list:    \n",
    "        new_k = new_k[0]\n",
    "    if new_k in all_gpes_freqs_iso3.keys():    #if the iso3 code is already in our new dictionary, then just cumulatively sum the frequencies\n",
    "        all_gpes_freqs_iso3[new_k] += v\n",
    "    else:                                      #else: if this is the first appearance of the iso3 code then just takes its frequency\n",
    "        all_gpes_freqs_iso3[new_k] = v\n",
    "    #newk = coco.convert(k, to = \"ISO3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. We can sort the dictionary of countries and their frequencies using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sorted(all_gpes_freqs_iso3.items(), key = lambda item: item[1], reverse = True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Let's place this information in a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsotu_countries_freqs_df = pd.DataFrame.from_dict(all_gpes_freqs_iso3, orient = 'index', columns = ['freq'])\n",
    "allsotu_countries_freqs_df.index.name = \"iso3\"\n",
    "allsotu_countries_freqs_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. We can't map the \"not founds\" so let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsotu_countries_freqs_df.drop(['not found'], inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. We can then merge the new dataframe with country frequencies (\"allsotu_countries_freqs_df\") with our original Geopandas dataframe of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataframes\n",
    "gdf_merged_all = gdf.merge(allsotu_countries_freqs_df, left_on = \"country_code\", right_index = True, how = \"outer\")\n",
    "\n",
    "#replace NaNs with 0s for the frequency column\n",
    "gdf_merged_all['freq'] = gdf_merged_all['freq'].fillna(0)\n",
    "\n",
    "#with NaNs replaced with 0s we can now convert all values in this column to integers\n",
    "gdf_merged_all['freq'] = gdf_merged_all['freq'].astype(int)\n",
    "\n",
    "#and let's remove any countries we do not have geographic location info (\"geometry\") for.\n",
    "gdf_merged_all = gdf_merged_all[gdf_merged_all['geometry'] != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can view this new dataframe, sorted by frequency:\n",
    "gdf_merged_all.sort_values(by = ['freq'], ascending = False).head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Patel]\n",
    "24. Convert the merged geodataframe into a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_json_all = json.loads(gdf_merged_all.to_json()) #Convert to String like object.\n",
    "print(type(gdf_json_all))\n",
    "json_data_all = json.dumps(gdf_json_all)\n",
    "print(type(json_data_all))\n",
    "json_data_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Patel]\n",
    "\n",
    "25. We can now create a chloropleth map using Bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the modules below were moved to the top of the notebook\n",
    "#from bokeh.io import output_notebook, show, output_file\n",
    "#from bokeh.plotting import figure\n",
    "#from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar\n",
    "#from bokeh.palettes import brewer  #Input GeoJSON source that contains features for plotting.\n",
    "\n",
    "geosource = GeoJSONDataSource(geojson = json_data_all)  \n",
    "#Define a sequential multi-hue color palette.\n",
    "palette = brewer['YlGnBu'][8]  \n",
    "#Reverse color order so that dark blue is highest obesity.\n",
    "palette = palette[::-1]  \n",
    "#Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors.\n",
    "color_mapper = LogColorMapper(palette = palette, low = 1, low_color = \"white\")   \n",
    "#Define custom tick labels for color bar.\n",
    "tick_labels = {'0': '0', '10':'10', '100':'100', '1000':'1000', '10000':'10000'}  \n",
    "#Create color bar. \n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8, width = 500, height = 20, \n",
    "                    border_line_color=None,location = (0,0), orientation = 'horizontal', major_label_overrides = tick_labels)  #Create figure object.\n",
    "p = figure(title = \"Countries mentioned in all SOTU address (1791 - 2023)\", plot_height = 600 , plot_width = 950, \n",
    "    toolbar_location = None)\n",
    "#remove grid lines\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None  \n",
    "#Add patch renderer to figure. \n",
    "p.patches('xs','ys', source = geosource,fill_color = {'field' :'freq', 'transform' : color_mapper},\n",
    "          line_color = 'black', line_width = 0.25, fill_alpha = 1)  \n",
    "#Specify figure layout.\n",
    "p.add_layout(color_bar, 'below')  \n",
    "#Display figure inline in Jupyter Notebook.\n",
    "output_notebook()  \n",
    "#Display figure.\n",
    "show(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><p style=\"color:green\">26. Examine the map above including the colors and scale used.</p>\n",
    "<ul> \n",
    "    <li style=\"color:green\">What conclusions could you draw from this map?</li>\n",
    "    <li style=\"color:green\">How might this map be deceiving?</li>\n",
    "    <li style=\"color:green\">What further questions do you have? How could you go about answering those questions?</li>\n",
    "</ul>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible options to fulfill weekly assignment for this week (talk to instructor):**\n",
    "1. Apply a NLP technique we learned about (place / person names using NER; Part-of-speech [POS] tagging) to a different corpus of your choice.\n",
    "2. Apply a NER technique to the SOTU corpus (but using a different technique than we learned about or applying it in a way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
