{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e914c3",
   "metadata": {},
   "source": [
    "# Text Analysis in Python 4: Topics & Emotions\n",
    "\n",
    "<h1 style=\"text-align:center;font-size:300%;\">The State of the Union is... scared??</h1> \n",
    "  <img src=\"https://api.time.com/wp-content/uploads/2016/07/emoticons.jpg?quality=85&w=600\" style=\"width:%80;\">\n",
    "  <!--<img src=\"http://www.languagetrainers.com/blog/wp-content/uploads/2012/10/us-are-vs-us-is1.png\" style=\"width:%140;\">-->\n",
    "\n",
    "\n",
    "\n",
    "## Topic Modeling, Sentiment Analysis, and other Inductive Approaches to Text Analysis\n",
    "\n",
    "To what extent can text analysis approaches identify topics, emotions, and other aspects of texts without any prior input by the researcher?\n",
    "\n",
    "In this session, participants will:\n",
    "+ learn what sentiment analysis and topic modeling can and can't do\n",
    "+ modify and interpret a series of sentiment analysis graphs\n",
    "+ briefly experiment with topic modeling while examining its limits\n",
    "\n",
    "<!--\n",
    "*Explain Topic Modeling / Give Examples Of (both good and bad)\n",
    "Present Buckets of Words Examples and have students interpret\n",
    "Apply Topic Modeling to SOTU Texts (does it make sense to do so? it certainly would be interesting to see which SOTU addresses are lumped in with which others)\n",
    "Compare to out-of-the-box approaches (Voyant, etc.)*-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ac6392",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><h3 style=\"color:green\">Code Together:</h3><p style=\"color:green\">In these cell blocks, we will code together. You can find the completed version in our shared folder (ending with \"_completed.ipynb\").</p></div>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercises:</h3><p style=\"color:blue\">are in blue text. These are a chance to practice what you have learned.</p></div>\n",
    "\n",
    "<div style = \"background-color:#f3e5f5\"><h3 style=\"color:purple\">Python Basics - Additional Practice</h3><p style=\"color:purple\">are in purple text. Work on these after the lesson if you would like more practice.</p></div>\n",
    "\n",
    "## Further Practice\n",
    "\n",
    "For further practice, we recommend you review the sections on [Sentiment Analysis](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/04-Sentiment-Analysis.html) and [Topic Modeling](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/05-Topic-Modeling.html) in Ch. 5 in Melanie Walsh's *Introduction to Cultural Analytics*. You can even practice with this code yourself by pressing the Rocket Ship icon at the top of each section and opening a [**Binder**](https://mybinder.org/) session which will allow you to run code in her Jupyter Notebooks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "397102e1",
   "metadata": {},
   "source": [
    "## Part I: Setup\n",
    "\n",
    "1. First, let's import all required libraries/packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os             #for navigating through files and working with file paths\n",
    "from pathlib import Path\n",
    "import nltk                    #Natural Language Toolkit - large package for text analysis and natural language processing\n",
    "import spacy                   # more NLP\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import re                      #re = regular expressions - a tool for searching for patterns in texts (i.e. remove all punctuation; identify all words that begin with a capitalized letter; identify phone numbers by searching for the pattern ###-###-####) \n",
    "import collections\n",
    "import gensim                  # for topic modeling \n",
    "import pandas as pd            #for working with dataframes\n",
    "import numpy as np             # for working with arrays of numbers (single dimension: array; 2d: matrix; 3+d: tensor)\n",
    "import matplotlib              #these 2 lines of code: importing Python libraries for visualization\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "nltk.download('punkt')         #nltk - here we need to download and import specific packages from nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "#from tqdm import notebook as tqdm   #for creating a progress bar to show computation in progress\n",
    "#from tqdm import trange\n",
    "\n",
    "plt.style.use('fivethirtyeight')    # sets the style for our plots, other style options here: https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html\n",
    "#%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 9]  #sets size of the visualizations in our notebook\n",
    "#%config InteractiveShellApp.matplotlib = 'inline'\n",
    "#%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7430068",
   "metadata": {},
   "source": [
    "2. ... and then open our dataframe with the fulltext and tokenized lists for each SOTU address. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf = pd.read_csv(\"sotudf.tsv\", encoding = \"utf-8\", sep = \"\\t\", index_col = 0, \n",
    "                     converters = {'tokens': literal_eval, 'ltoks': literal_eval, 'ltoks_ns': literal_eval})\n",
    "#converters needed otherwise pandas reads in a list of tokens [gentlemen, of, the, ...] and surrounds each word with quotation marks\n",
    "## like ['gentlemen', 'of', 'the', ...] which creates all kinds of problems\n",
    "sotudf.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ede3358",
   "metadata": {},
   "source": [
    "3. As you may recall, there is one empty text file in our dataset. Since Washington did not give a SOTU address in 1790, the person who compiled this SOTU corpus created an empty text file for 1790 to indicate that the 1790 address was not forgotten, but simply was never given.\n",
    "\n",
    "For our sentiment analysis, however, we want to remove all null data (in this case the 1790 dummy file). We can do that using the **.notnull() function. When subsetting a dataframe, a simple way to see how it changed is to compare the dimensions of the dataframe (number of rows and columns) before and after applying the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c37b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sotudf.shape)\n",
    "sotudf = sotudf[sotudf['fulltext'].notnull()]\n",
    "print(sotudf.shape)  #after removing empty 1790 row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92d64b4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3  style=\"color:green\">Code Together</h3>\n",
    "\n",
    "<p style=\"color:green\"> 4. Using the <a href = \"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\">Python Pandas Cheat Sheet (click here)</a>, inspect our SOTU dataframe (\"sotudf\") retrieving the number of rows and columns and the types of data stored in each column.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a694c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3716fa47",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "\n",
    "<p style=\"color:green\"> 5. Using the <a href = \"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\">Python Pandas Cheat Sheet (click here)</a>, can you identify if all lists of tokens are unique? (If they aren't then that indicates we made an error in compiling the dataset.)</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb2ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110dc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e56c8e81",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p style=\"color:green\"> 6. Next, we will create two new columns:\n",
    "<ol style=\"color:green\">\n",
    "    <li>one that calculates the number of characters (rather than words) for each SOTU address</li>\n",
    "    <li>another that calculates the average word-length of each address</li>\n",
    "</ol>\n",
    "<p style=\"color:green\"><i>To do this, we can call an anonymous function using <b>lambda</b> within the <b>.apply()</b> method. There are other ways that are faster</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2f9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c461f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a21dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af617a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eb5f265",
   "metadata": {},
   "source": [
    "## Part II. Sentiment Analysis - An Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99188bd3",
   "metadata": {},
   "source": [
    "7. **Sentiment Analysis** is a text analysis method that assigns emotional scores to segments of texts. \n",
    "\n",
    "The most common sentiment analysis tools assign words and phrases a sentiment score ranging from positive to negative. The VADER lexicon, for example, assign relies on a dataset of phrases coded by human readers between extremely positive (+4) and extremely negative (-4). You can learn more about VADER and practice with it in the [Sentiment Analysis](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/04-Sentiment-Analysis.html) section in Melanie Walsh's *Cultural Analytics* ebook.\n",
    "\n",
    "Other sentiment analysis tools can identify more nuanced emotions. For example, in this lesson, we will be using the [NRC Word-Emotion Association Lexicon](https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm). According to this lexicon's webpage:\n",
    "\n",
    "```\n",
    "The NRC Emotion Lexicon is a list of English words and their associations with eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive). The annotations were manually done by crowdsourcing.\n",
    "```\n",
    "\n",
    "The code below, which uses the NRC, was borrowed and adapted from Greg Rafferty's sentiment analysis of the Harry Potter novels: https://github.com/raffg/harry_potter_nlp/blob/master/sentiment_analysis.ipynb."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1220b44",
   "metadata": {},
   "source": [
    "## Part III: Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7610b6bb",
   "metadata": {},
   "source": [
    "8. We've already done a lot of the necessary pre-processing of our SOTU addresses (tokenizing, lower-casing, removing stopwords, etc.). Let's review what our SOTU dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a45043",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8267832",
   "metadata": {},
   "source": [
    "9. We could run sentiment analysis on our lower-case tokens with stopwords removed (the column: \"ltoks_ns\"). However, what about distinguishing plural (\"citizens\", \"people\", \"gentlemen\") from singular forms (\"citizen\", \"person\", \"gentleman\") forms of nouns? What about different conjugations of the same verb ([be, am, is, are, was, were], [play, plays, played])?\n",
    "\n",
    "To group together words that have a common root, we can *lemmatize* each word, that is convert it to its *lemma*. One way to do this is to use NLTK's **WordNetLemmatizer** to return the lemma of each word. Let's see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"play\", \"plays\", \"player\", \"players\", \"played\", \"playable\", \"rocks\", \"corpora\", \"better\", \"be\", \"am\", \"is\", \"were\", \"are\", \"break\", \"breaks\", \"broke\", \"broken\", \"citizen\", \"citizens\", \"women\", \"women\",\n",
    "         \"cactus\", \"cacti\", \"disturb\", \"disturbs\", \"disturbing\", \"go\", \"goes\", \"went\"]\n",
    "[nltk_lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29168245",
   "metadata": {},
   "source": [
    "10. Not perfect, but it does simplify our word list a little bit. For more advanced projects, you could try using **spaCy**'s lemmatizing functions that also read in the Part of Speech (POS) tag for each word. I.e., reading in (\"scared\", \"ADJ\") will produce different results than (\"scared\", \"VERB\").\n",
    "\n",
    "But, for this project, NLTK's lemmatizer will work well enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf['lemmas'] = sotudf['ltoks_ns'].apply(lambda x: [nltk_lemmatizer.lemmatize(ltok) for ltok in x])\n",
    "sotudf.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "444fb09e",
   "metadata": {},
   "source": [
    "11. Let's create a frequency list of each lemma using **collections.Counter()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b886f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf['freqlemmas'] = sotudf['lemmas'].apply(lambda x: collections.Counter(x))\n",
    "sotudf.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b227fd5f",
   "metadata": {},
   "source": [
    "12. Now, let's subset our dataframe by only keeping those columns we need.\n",
    "\n",
    "*Note: we could also subset our dataframe this way:*\n",
    "\n",
    "```\n",
    "sotusub = sotudf[['year', 'pres', 'numtoks', 'freqlemmas']]\n",
    "```\n",
    "\n",
    "*However, this could cause errors later, so it is better to create subsets using the **.loc[]** method.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotusub = sotudf.loc[:,['year', 'pres', 'numtoks', 'freqlemmas']]\n",
    "sotusub.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdd24085",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" style='color:blue'><h3>Exercises for Part III</h3>\n",
    "\n",
    "<p>13. Create a new column to store an all upper-case version of our fulltext strings in the 'full_text' column.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811330c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df57832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93ccbe18",
   "metadata": {},
   "source": [
    "## Part IV: Applying Sentiment Analysis to the SOTU Corpus\n",
    "\n",
    "Our data is now ready for sentiment analysis.\n",
    "\n",
    "The code below gets a little complicated. In essence it creates a function **corpus_emo_scores** that reads in a dataframe and column name (which identifies the column in the dataframe the frequency dictionary of lemmatized words from each text). It also reads in the NRC Emotions Lexicon that we will use to apply emotions scores to each of our texts.\n",
    "\n",
    "It then calls the **emo_score_by_text** function, which scores each text for the eight emotions and two sentiments included in the NRC Emotions Lexicon. This in turn call the function **emo_score**.\n",
    "\n",
    "14. Let's run the code below to place three new functions into memory. Then we will examine exactly how it works more closely.\n",
    "\n",
    "**Note: Before running this, you will need to download the [NRC Emotion Lexicon](https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ef7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_score(lemma, freq, emolex_words):\n",
    "    '''\n",
    "    INPUT: lemmatized, lower-cased word (lemma) + frequency this lemma appears in a text\n",
    "    OUTPUT: list of 10 NRC emotions scores (8 emotions + 2 sentiments [positive / negative])\n",
    "\n",
    "    reads in a lemmatized word, looks it up in NRC lexicon dictionary (emolex_words) and returns the score of the word\n",
    "    for the 8 emotions and 2 sentiments in the lexicon\n",
    "\n",
    "    then takes the resulting list of 10 scores and multiples each by the frequency of the word\n",
    "    returning the new list\n",
    "\n",
    "    '''\n",
    "    if (emolex_words[ 'word'].eq(lemma)).any():   #if any word in the \"word\" column in emolex_words equals the inputted lemma:\n",
    "        #print(lemma)\n",
    "        emolex_row = emolex_words[emolex_words['word'] == lemma].loc[:,'anger':'trust']\n",
    "        #print(emolex_row)\n",
    "        emolex_list = [item for item in emolex_row.iloc[0]]\n",
    "        new_emo_scores = [item * freq for item in emolex_list]\n",
    "        #print(new_emo_scores, \"\\n\")\n",
    "        #emo_scores = [x + y for x,y in zip(emo_scores, new_emo_scores)]\n",
    "        return(new_emo_scores)\n",
    "    else:                                          #else: lemma not in emolex_words dataframe\n",
    "        return(None)\n",
    "\n",
    "def emo_score_by_text (lemmadict, emolex_words):\n",
    "    '''\n",
    "    INPUT: reads in a frequency dictionary of lemmatized words (lemmadict)\n",
    "    OUTPUT: returns a list of 10 cumulative scores for each of the 8 emotions and 2 sentiments in the NRC lexicon\n",
    "\n",
    "\n",
    "    '''\n",
    "    cum_emo_score = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for key, val in lemmadict.items():\n",
    "        temp_emo_score = emo_score(key, val, emolex_words)\n",
    "        if temp_emo_score is not None:\n",
    "            cum_emo_score = [x + y for x, y in zip(cum_emo_score, temp_emo_score)]\n",
    "    return(cum_emo_score)\n",
    "\n",
    "def corpus_emo_scores(df, freq_lemmas_col):\n",
    "    '''\n",
    "    INPUT: a dataframe of texts (df), with a column name (freq_lemmas_col) indicating a column\n",
    "    with a frequency dictionary of lemmatized words for each text\n",
    "    OUTPUT: returns df with a new column recording the total 10 NRC scores for each text\n",
    "    '''     \n",
    "    new_df = df.copy()\n",
    "    filepath = Path('NRC-Emotion-Lexicon','NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
    "    \n",
    "    emolex_df = pd.read_csv(filepath,\n",
    "                            names=[\"word\", \"emotion\", \"association\"],\n",
    "                            sep='\\t')\n",
    "    emolex_words = emolex_df.pivot(index='word',\n",
    "                                   columns='emotion',\n",
    "                                   values='association').reset_index()\n",
    "    #emotions = emolex_words.columns.drop('word')\n",
    "    #emo_df = pd.DataFrame(0, index = sotudf.index, columns = emotions)    ## Let's replace that with the name of our dataframe (\"sotudf\")\n",
    "\n",
    "    #new_df['emo_score'] = new_df[freq_lemmas_col].apply(emo_score_by_text)\n",
    "    new_df['emo_score'] = new_df.apply(lambda x: emo_score_by_text(x[freq_lemmas_col], emolex_words), axis = 1)\n",
    "    return(new_df)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c481d4e7",
   "metadata": {},
   "source": [
    "15. Let's apply these functions to our corpus. Unfortunately, it takes 10-20 minutes to run this code on the whole corpus. So, let's just test it on the first three texts in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61902dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sotusub2 = corpus_emo_scores(sotusub, \"freqlemmas\")          #this runs through the whole corpus. this takes 10-20 minutes\n",
    "sotusub2 = corpus_emo_scores(sotusub.iloc[0:3], \"freqlemmas\")  #instead we can test it on just the first three texts\n",
    "sotusub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc9b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98acef43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p style=\"color:green\">16. For each text in our corpus, this function retrieves scores for each of the 10 NRC categories (saved as a list in the \"emo_score\" column). It does so by passing the NRC Emotions Lexicon (saved as \"emolex_words\") and the column from our SOTU dataframe with the lemmas and their frequencies.</p>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1143721d",
   "metadata": {},
   "source": [
    "17. We can split the list of emo_scores into separate columns for each emotion / sentiment using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotusub2[['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust']] = pd.DataFrame(sotusub2.emo_score.tolist(), index = sotusub2.index)\n",
    "sotusub2 = sotusub2.drop(columns = ['emo_score'])\n",
    "sotusub2.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5023545c",
   "metadata": {},
   "source": [
    "It would be an interesting exercise to compare these automatically calculated NRC scores (derived from texts of these addresses) to scores given by humans who watched these addresses live. Obviously, sentiment analysis does not catch sarcasm, derision, and tone in general."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb8bc3ca",
   "metadata": {},
   "source": [
    "18. To save time running the sentiment analysis function across the entire dataframe, rather than just the three texts above, we can just load the results and examine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then load nrc sentiment analysis results\n",
    "sotusub2=pd.read_csv(\"sotu_nrc_full.csv\",encoding = \"utf-8\")   #these are the full results from the text_emotion function\n",
    "sotusub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e14403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e50b31a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3 style=\"color:green\">Code Together</h3>\n",
    "\n",
    "<p style=\"color:green\">19. Before visualizing the sentiment analysis, it may be useful to review the functions we defined in Step 14 and ran in Step 15. Notice first, in Step 15, we called the function \"corpus_emo_scores.\" That function called another function, \"emo_score_by_text,\" which, in turn, called the function, \"emo_score.\"  Review the documention, in triple quotes, for each function to understand what they do. </p>\n",
    "\n",
    "<p style=\"color:green\">Let's examine some parts of these functions. First, the outermost function, \"corpus_emo_scores\" reads in the NRC Emotion Lexicon (see below), which awards ones or zeroes to thousands of English words to indicate whether they invoke any of eight emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust) or one of two sentiments (positive or negative).</p>\n",
    "\n",
    "<p style=\"color:green\">To get a better idea how the NRC Emotion Lexicon assigns scores, let's use the folder directory on the left side of JHub to navigate to the NRC Emotion Lexicon dataset. <i>What potential problems do you anticipate would result from such an approach to sentiment analysis?</i></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('NRC-Emotion-Lexicon','NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
    "    \n",
    "emolex_df = pd.read_csv(filepath,\n",
    "                            names=[\"word\", \"emotion\", \"association\"],\n",
    "                            sep='\\t')\n",
    "print(\"***emolex df: \",emolex_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b30614",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p style=\"color:green\">19b. As you can see the <b>.pivot()</b> method converts emolex_df from long to wide.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_words = emolex_df.pivot(index='word',\n",
    "                                   columns='emotion',\n",
    "                                   values='association').reset_index()\n",
    "emolex_words.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2291562e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p style=\"color:green\">19c. Then, it extracts a list of the 8 emotions / 2 sentimensts from this dataset\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = emolex_words.columns.drop('word')\n",
    "print(\"\\n***list of emotions to be used as column names :\",emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ec0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff57646d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<p style=\"color:green\">20. So, for example, if the address by Lincoln in 1863 uses the word \"abandon\", this code will retrieve the NRC scores for abandon: </p>\n",
    "\n",
    "```\n",
    "abandon\tanger\t0\n",
    "abandon\tanticipation\t0\n",
    "abandon\tdisgust\t0\n",
    "abandon\tfear\t1\n",
    "abandon\tjoy\t0\n",
    "abandon\tnegative\t1\n",
    "abandon\tpositive\t0\n",
    "abandon\tsadness\t1\n",
    "abandon\tsurprise\t0\n",
    "abandon\ttrust\t0\n",
    "```\n",
    "\n",
    "<p style=\"color:green\">It then will add 1 to the \"fear\", \"sadness\", and \"negative\" scores for the Lincoln 1863 address.</p>\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de94628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "461eafc4",
   "metadata": {},
   "source": [
    "22. Back to our dataframe of SOTU addresses and their respective emotion / sentiment scores. Frequently, in data science, calculating percentages or proportions is more meaningful than working with absolute numbers. Otherwise, our calculated emo scores may better reflect the length of each address than the actual emotional tenor of each given speech. \n",
    "\n",
    "Let's replace the absolute counts with each emotion's score divided by the number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust']\n",
    "for emotion in emotions:\n",
    "    sotusub2[emotion] = sotusub2[emotion] / sotusub2['numtoks']\n",
    "sotusub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotusub2 = sotusub2.sort_values(by = \"year\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40411f74",
   "metadata": {},
   "source": [
    "23. Finally, we can plot these sentiment scores. Here we will use the **Matplotlib** library (plt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff836bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotusub2['pres_year'] = sotusub2['pres']  + \" \" + sotusub2['year'].astype(str)\n",
    "# length = sum([len(sotudf3['word_count'])])\n",
    "x = sotusub2['year'].tolist()\n",
    "for emotion in emotions:\n",
    "    y = sotusub2[emotion]\n",
    "    plt.plot(x,y,label = sotusub2['pres_year'])\n",
    "    plt.title('{} sentiment of State of the Union Addresses'.format(emotion, fontsize=24))\n",
    "    plt.xlabel('Year', fontsize=15)\n",
    "    plt.ylabel('Average Sentiment', fontsize=15)\n",
    "    plt.legend(loc='best', fontsize=15, bbox_to_anchor=(1.05, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad77fa80",
   "metadata": {},
   "source": [
    "24. We can also <b style=\"color:red\">color</b><b style=\"color:blue\">-code</b> <b style=\"color:green\">this</b> <b style=\"color:orange\">data</b> <b style=\"color:purple\">by president</b>. We can use the **.shift()** and **.cumsum()** functions to label each administration and then the **groupby()** function to create a list of years for each successive presidential administration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f49acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotusub2[\"presnum\"] = (sotusub2[\"pres\"] != sotusub2[\"pres\"].shift()).cumsum()\n",
    "presdf = sotusub2[[\"pres\",\"year\",\"presnum\",\"pres_year\"]]\n",
    "presdf.to_csv(\"pres_sotulist.csv\",encoding='utf-8')\n",
    "presyears = presdf.groupby('presnum')['year'].apply(list)\n",
    "print(presyears[-10:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bad155d",
   "metadata": {},
   "source": [
    "25. Now, we can modify our plot code from above to color-code each presidential administration and to add a line to show the moving average of each emotion or sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed32132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingaverage(interval, window_size):\n",
    "    window = np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'same')\n",
    "\n",
    "x = sotusub2['year'].tolist()\n",
    "for emotion in emotions:\n",
    "    fig,ax = plt.subplots()\n",
    "    y = sotusub2[emotion]\n",
    "    ctr=0\n",
    "    plt.plot(x,y,label = sotusub2['pres_year'], linestyle = 'dashed', linewidth=2, color = 'gray')\n",
    "    for presyrs in presyears:\n",
    "        plt.plot(presyrs, y[ctr:ctr+len(presyrs)],label = sotusub2.iloc[ctr]['pres'],linewidth=2)\n",
    "        ctr+=len(presyrs)\n",
    "    plt.plot(x,movingaverage(y, 10), color='k', linewidth=2, linestyle=':', label = 'Moving Average')\n",
    "    plt.title('{} sentiment of State of the Union Addresses'.format(emotion, fontsize=24))\n",
    "    plt.xlabel('Year', fontsize=15)\n",
    "    plt.ylabel('Average Sentiment', fontsize=15)\n",
    "    plt.legend(loc='best', fontsize=7, bbox_to_anchor=(1.05, 1))\n",
    "    image_format = \"png\"\n",
    "    image_name = \"sotu_%s_sentiment.%s\"%(emotion,image_format)\n",
    "    fig.savefig(image_name, format=image_format, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f751824b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" style='color:blue'><h3>Exercise for Part IV</h3>\n",
    "\n",
    "<p>26. Copying and pasting some of the relevant code from above, create a single plot combining positive and negative sentiment scores to identify which presidents used the most emotional language.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d3049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "92ccb6e3f8e1ba46ac70611fe300a00d231540f34c9f821035b67580ebdf166e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
